{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2G3naCwbU7E5Wwt7jRpvU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-r-soares/desafio_etl_python/blob/main/DesafioETLPython.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxzdvHs4dBAa"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "\n",
        "# --- CONFIGURAÇÃO ---\n",
        "GOOGLE_API_KEY = \"AI_STUDIO_API_KEY_AQUIm-MMbVxZOej1BynUk8\" # <--- INSIRA SUA CHAVE AQUI NOVAMENTE\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.5-flash-lite')"
      ],
      "metadata": {
        "id": "wYokQao-dhzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_dados_clientes():\n",
        "    clientes = []\n",
        "\n",
        "    # 20 Clientes Churn (Já cancelaram)\n",
        "    for i in range(1, 6):\n",
        "        clientes.append({\n",
        "            \"id\": i,\n",
        "            \"nome\": f\"Cliente {i}\",\n",
        "            \"status_atual\": \"Churn\",\n",
        "            \"dias_sem_transacao\": random.randint(30, 90),\n",
        "            \"reclamacoes_ultimo_mes\": random.randint(1, 5),\n",
        "            \"saldo_medio\": 0\n",
        "        })\n",
        "\n",
        "    # 25 Clientes Risco (Probabilidade de Churn)\n",
        "    for i in range(6, 15):\n",
        "        clientes.append({\n",
        "            \"id\": i,\n",
        "            \"nome\": f\"Cliente {i}\",\n",
        "            \"status_atual\": \"Risco\",\n",
        "            \"dias_sem_transacao\": random.randint(15, 29),\n",
        "            \"reclamacoes_ultimo_mes\": random.randint(1, 3),\n",
        "            \"saldo_medio\": random.uniform(100, 1000)\n",
        "        })\n",
        "\n",
        "    # 55 Clientes Normais\n",
        "    for i in range(15, 21):\n",
        "        clientes.append({\n",
        "            \"id\": i,\n",
        "            \"nome\": f\"Cliente {i}\",\n",
        "            \"status_atual\": \"Normal\",\n",
        "            \"dias_sem_transacao\": random.randint(0, 5),\n",
        "            \"reclamacoes_ultimo_mes\": 0,\n",
        "            \"saldo_medio\": random.uniform(2000, 10000)\n",
        "        })\n",
        "\n",
        "    return clientes\n",
        "\n",
        "# Salva o arquivo inicial (simulando a Extração futura)\n",
        "dados_brutos = gerar_dados_clientes()\n",
        "with open('clientes_brutos.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(dados_brutos, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Massa de dados gerada com sucesso!\")"
      ],
      "metadata": {
        "id": "QUEejGxBed4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. EXTRACT (Extração) ---\n",
        "print(\"Iniciando Extração...\")\n",
        "with open('clientes_brutos.json', 'r', encoding='utf-8') as f:\n",
        "    dados_entrada = json.load(f)\n",
        "\n",
        "dados_processados = []\n",
        "\n",
        "# --- 2. TRANSFORM (Transformação com IA) ---\n",
        "for i, cliente in enumerate(dados_entrada):\n",
        "    plano_acao = \"Cliente inativo/Churn.\" # Valor padrão\n",
        "\n",
        "    # Processa apenas se NÃO for Churn\n",
        "    if cliente['status_atual'] in ['Risco', 'Normal']:\n",
        "\n",
        "        # Define o prompt\n",
        "        if cliente['status_atual'] == 'Risco':\n",
        "            prompt = f\"Atue como um gerente de banco sênior. O cliente {cliente['nome']} está em RISCO de churn. Dados: {cliente['dias_sem_transacao']} dias sem movimentar, {cliente['reclamacoes_ultimo_mes']} reclamações recentes. Crie uma mensagem curta (máximo 20 palavras) e direta de ação para retenção.\"\n",
        "        else:\n",
        "            prompt = f\"Atue como um gerente de banco. O cliente {cliente['nome']} é NORMAL e fiel. Saldo médio: R$ {cliente['saldo_medio']:.2f}. Sugira um produto de investimento em uma frase curta (máximo 20 palavras).\"\n",
        "\n",
        "        # --- Lógica de Retentativa (Retry Loop) ---\n",
        "        sucesso = False\n",
        "        tentativas = 0\n",
        "\n",
        "        while not sucesso and tentativas < 3: # Tenta até 3 vezes o mesmo cliente\n",
        "            try:\n",
        "                # Faz a chamada à API\n",
        "                response = model.generate_content(prompt)\n",
        "\n",
        "                if response.text:\n",
        "                    plano_acao = response.text.strip().replace('\"', \"'\").replace('\\n', ' ')\n",
        "                else:\n",
        "                    plano_acao = \"Sem sugestão gerada.\"\n",
        "\n",
        "                sucesso = True # Sai do loop while\n",
        "\n",
        "                # Pausa de SUCESSO (15s para respeitar o limite de ~4 req/min do modelo novo)\n",
        "                time.sleep(15)\n",
        "\n",
        "            except Exception as e:\n",
        "                erro_str = str(e)\n",
        "                if \"429\" in erro_str:\n",
        "                    print(f\"⚠️ Cota excedida no cliente {cliente['id']}. Esperando 60s para esfriar...\")\n",
        "                    time.sleep(65) # Espera 1 minuto e 5 segundos\n",
        "                    tentativas += 1\n",
        "                else:\n",
        "                    print(f\"❌ Erro irrecuperável no ID {cliente['id']}: {erro_str}\")\n",
        "                    plano_acao = \"Erro técnico na análise.\"\n",
        "                    sucesso = True # Força saída para não travar\n",
        "                    time.sleep(5)\n",
        "\n",
        "    # Adiciona ao novo dataset\n",
        "    novo_cliente = cliente.copy()\n",
        "    novo_cliente['analise_ia'] = plano_acao\n",
        "    dados_processados.append(novo_cliente)\n",
        "\n",
        "    # Mostra progresso\n",
        "    print(f\"Cliente {cliente['id']} processado. Status: {cliente['status_atual']}\")\n",
        "\n",
        "# --- 3. LOAD (Carga) ---\n",
        "print(\"Iniciando Carga...\")\n",
        "with open('clientes_analisados.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(dados_processados, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"\\nETL Finalizado com Sucesso! Arquivo 'clientes_analisados.json' gerado.\")"
      ],
      "metadata": {
        "id": "oHMv6yxXYmq4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}